---
title: "Snowflakeã‚’ç”¨ã„ãŸVCFãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®éºä¼å­ãƒãƒªã‚¢ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã¨è¡¨ç¾å‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ã®çµ±åˆ"
emoji: "ğŸ§¬"
type: "tech"
topics:
  - "snowflake"
  - "ãƒã‚¤ã‚ªã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹"
  - "rnaseq"
  - "ãƒãƒªã‚¢ãƒ³ãƒˆè§£æ"
  - "ã‚²ãƒãƒ "
published: true
published_at: "2023-07-15 17:22"
---

ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢å…¼ãƒã‚¤ã‚ªã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚·ãƒ£ãƒ³ã®æ˜¯æã§ã™ã€‚

æ¥­å‹™ã§snowflakeã‚’è§¦ã£ã¦ã„ã¾ã™ãŒã€snowflakeã®æ€§èƒ½ã¯ç´ æ™´ã‚‰ã—ã„ã‚‚ã®ãŒã‚ã‚Šã¾ã™ã€‚ä¸€æ–¹ã§ã€ç§ã¯ç”Ÿç‰©ç³»ç ”ç©¶è€…ã§ã‚‚ã‚ã‚Šã€æ™®æ®µã¯ãƒã‚¤ã‚ªã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹ã§ç ”ç©¶ã—ã¦ã„ã¾ã™ã€‚ã‚²ãƒãƒ ãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã£ãŸè§£æã‚’ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã®åŠ›ã§è§£æã™ã‚‹ã“ã¨ãŒãƒ¡ã‚¤ãƒ³ã§ã™ãŒã€ãµã¨ã€snowflakeã‚’ä½¿ãˆã°ã‚‚ã£ã¨ã„ã„è§£æãŒã§ãã‚‹ã®ã§ã¯...?ã¨æ€ã†ã“ã¨ãŒå¢—ãˆã¦ãã¦ã„ã¾ã™ã€‚ãã“ã§snowflakeã§ã§ãã‚‹ãƒã‚¤ã‚ªã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹ã«ãƒãƒ£ãƒ¬ãƒ³ã‚¸ã—ã¦snowflakeã¨ãƒã‚¤ã‚ªã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹ã®ã‚³ãƒ©ãƒœãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®å¯èƒ½æ€§ã‚’æ¢ã£ã¦ã¿ãŸã„ã¨æ€ã„ã¾ã™ã€‚å‰åŠã¯VCFãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®éºä¼å­ãƒãƒªã‚¢ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã¨ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’snowflakeä¸Šã§çµ±åˆã—ã¦ã¿ã¾ã™ã€‚å¾ŒåŠã¯ã€snowflakeã§ãƒã‚¤ã‚ªã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹ã«é–¢ã—ã¦å€‹äººçš„æ„è¦‹ã‚’è¿°ã¹ã¾ã™ã€‚

ãƒãƒ³ã‚ºã‚ªãƒ³ã¯åŸºæœ¬çš„ã«ã¯ã“ã¡ã‚‰ã®ãƒãƒªã‚¢ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿è§£æã®è¨˜äº‹ã®å†…å®¹ã«å‰‡ã£ã¦è§£æã‚’é€²ã‚ã¾ã™ã€‚Snowflakeã§å®Ÿéš›ã®ã‚²ãƒãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å–ã‚Šè¾¼ã¿ã€ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®ä¾‹ã‚’èª¬æ˜ã—ã¦ã„ã¾ã™ã€‚ãƒˆãƒ©ã‚¤ã‚¢ãƒ«ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã§1æ™‚é–“ãã‚‰ã„ã§å®Ÿè¡Œã§ãã¾ã—ãŸã€‚
https://www.snowflake.com/blog/leveraging-snowflake-enable-genomic-analytics-scale/?lang=ja

:::message
**ãƒãƒ³ã‚ºã‚ªãƒ³ã‚’è¡Œã†å‰ã«**
VCF ãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã†ã«ã¯ã€ã¾ãšç”Ÿãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã«é©ç”¨ã™ã‚‹å–ã‚Šè¾¼ã¿ã¨è§£æé–¢æ•°ã‚’ Snowflake ã§å®šç¾©ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ä¸‹è¨˜ã‚³ãƒãƒ³ãƒ‰ã‚’Snowflake UI ã§å®Ÿè¡Œã—ã¦Java ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å–å¾—ã—ã¦ãã ã•ã„ã€‚ã¡ãªã¿ã«å®šç¾©ã™ã¹ãè§£æé–¢æ•°ã¯3ã¤ã‚ã‚Šã¾ã™ã®ã§ã€å…¨ã¦å®Ÿè¡Œã—ã¦å®šç¾©ã™ã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚
:::details Sample Functions for VCF File Data Ingestion:
-- Copyright (c) 2022 Snowflake Inc.  All Rights Reserved


-- UDTF to ingest gzipped vcf file.  If num_lines > 0, only first N data lines are processed
create or replace function ingest_vcf(vcfFile string, num_lines integer)
returns table (chrom string, pos integer, id string, ref string, alt string, qual string,
                   filter string, info variant, sampleVals variant, sampleId string)
language java
handler='App'
target_path='@~/ingest_vcf.jar'
as
$$
import java.io.*;
import java.util.*;
import java.util.zip.GZIPInputStream;
import java.util.stream.Stream;


class OutputRow {
   public String chrom; 
   public int    pos;      
   public String id; 
   public String ref; 
   public String alt;  
   public String qual;  
   public String filter;
   public String info;
   public String sampleVals;
   public String sampleId;


   public OutputRow(String chrom, int pos, String id, String ref, String alt, String qual,
                     String filter, String info, String sampleVals, String sampleId) {


       this.chrom      = chrom; 
       this.pos        = pos;   
       this.id         = id;  
       this.ref        = ref;   
       this.alt        = alt;  
       this.qual       = qual;  
       this.filter     = filter;
       this.info       = info;
       this.sampleVals = sampleVals;
       this.sampleId   = sampleId;


   }
}


class DictEntry {
   public String number;
   public String type;
   public String description; 
  
   public DictEntry(String number, String type, String description) {
       this.number = number;
       this.type = type;
       this.description = description;
   }
}


public class App {


   public static Class getOutputClass() {
       return OutputRow.class;
   }


   // Return quoted values unless numeric, to populate JSON values
   // Also replace "dots" with empty strings
   public static String delimitedValue(String rawValue, String type) {
       String theValue = (rawValue.equals(".")) ? "" : rawValue;
       return ((type.equals("Integer") || type.equals("Float")) ? theValue : "\"" + theValue + "\"");
   }


   // Assemble a Json Output object element from a VCF element
   public static String createJsonElement(String theKey, String unparsedValue, Map<String, DictEntry> dict) {


       // Lookup metadata in the dictionary
       String theNumber = dict.get(theKey).number;
       String theType = dict.get(theKey).type;


       String theValue = (theNumber.equals("0") ? "" : unparsedValue);


       if (theNumber.equals("0")) { // Boolean
           return("\"" + theKey + "\": true");
       }
       else if (theNumber.equals("1")) { // Singleton
           return("\"" + theKey + "\": " + delimitedValue(theValue, theType));
       }
       else { // Array of values
           List<String> vals = new ArrayList<String>();
               for (String e : theValue.split(",")) {
                   vals.add(delimitedValue(e, theType));
               }
           return("\"" + theKey + "\": [" + String.join(",", vals) + "]");
       }
   }


   // Parse content of Info fields into JSON
   public static String createInfoJson(Map<String, DictEntry> dict, String infoText) {
       if (infoText.equals(".")) {
           return null;
       }
       List<String> elements  = new ArrayList<String>();
       String[] infoArray = infoText.split(";");
       for (String item : infoArray) {
          String theKey = item.split("=")[0].trim();
          String unparsedValue = (item.contains("=") ? item.split("=")[1].trim() : "");
          elements.add(createJsonElement(theKey, unparsedValue, dict));
       }
       return ("{" + String.join(",", elements) + "}");
   }


   // Parse genomic values based on Format field into Json
   public static String createFormatJson(Map<String, DictEntry> dict, String formatString, String formatVals) {
       List<String> elements = new ArrayList<String>();
       String[] formatArray = formatString.split(":");  // available fields
       String[] valsArray = formatVals.split(":"); // the values -- may be truncated relative to format entries
       for (int i = 0 ; i < valsArray.length; i++ ) {
           String theKey = formatArray[i];
           String unparsedValue = valsArray[i];
           // add an entry to the JSON so long as the field is not empty (!== ".")
           if (! unparsedValue.equals(".")) {
               elements.add(createJsonElement(theKey, unparsedValue, dict));                   
           }  
       }                  
       return ("{" + String.join(",", elements) + "}");
   }


   // Parse a line from header INFO or FORMAT entries and populate the respective dictionaries
   public static void addDictionaryElement(Map<String, DictEntry> dict, String descriptor) {
       String infoData = descriptor.split("=<")[1];
       dict.put(infoData.split("ID=")[1].split(",")[0],
               new DictEntry(
                   infoData.split("Number=")[1].split(",")[0],
                   infoData.split("Type=")[1].split(",")[0],
                   infoData.split("Description=")[1].split(">$")[0]
               ));       
   }


   public static Stream<OutputRow> process(InputStream vcfFile, long num_lines) throws IOException {


       Map<String, DictEntry> infos = new HashMap<>();
       Map<String, DictEntry> formats = new HashMap<>();


       try {
           GZIPInputStream gzStream = new GZIPInputStream(vcfFile);
           Reader vcf = new InputStreamReader(gzStream, "US-ASCII");
           BufferedReader vcfBuf = new BufferedReader(vcf);
           String thisLine = null;
           while ((thisLine = vcfBuf.readLine()) != null) {
               if (! thisLine.startsWith("##")) {
                   break;
               }
               else if (thisLine.startsWith("##INFO")) {
                   addDictionaryElement(infos, thisLine);
               }
               else if (thisLine.startsWith("##FORMAT")) {
                   addDictionaryElement(formats, thisLine);
               }               
           }
          
           if (! thisLine.startsWith("#CHROM")) {
               throw new IOException("Unknown VCF Layout, expected '#CHROM' header line");
           }


           final String[] columns = thisLine.split("#")[1].split("\t");


           // Map the position of all "Well Known Columns"
           Map<String,Integer> columnIndex = new HashMap<>(10);
           String knownCols = "CHROM, POS, ID, REF, ALT, QUAL, FILTER, INFO, FORMAT";
           for (int i = 0; i < columns.length; i++) {
               columnIndex.put(columns[i],i);
               if (knownCols.indexOf(columns[i]) == -1) {
                   break;
               }
           }


           // 0-based index of first sample positon for single or multisample VCF
           // Add some validation...
           final int firstSampleCol = (columns.length > 9) ? 9 :
           (columns.length == 9 && columnIndex.get("FORMAT") == null) ? 8 : -1;


           // Handle the data lines
          
           return ((num_lines == 0) ? vcfBuf.lines() : vcfBuf.lines().limit(num_lines)).flatMap( dataLine -> {
               String[] vals = dataLine.split("\t");
               // Get the sample-independent data
               String chrom  =  vals[columnIndex.get("CHROM")];
               int pos       =  Integer.parseInt(vals[columnIndex.get("POS")]);
               String id     =  vals[columnIndex.get("ID")];
               String ref    =  vals[columnIndex.get("REF")];
               String alt    =  vals[columnIndex.get("ALT")];     
               String qual   =  vals[columnIndex.get("QUAL")];  
               String filter =  vals[columnIndex.get("FILTER")];  
               String info   =  createInfoJson(infos, vals[columnIndex.get("INFO")]);
               return java.util.stream.IntStream.range((firstSampleCol >= 0 ? firstSampleCol : columns.length - 1), columns.length)
                   .mapToObj( i -> {
                       String format =  (columnIndex.get("FORMAT") == null) ? null : vals[columnIndex.get("FORMAT")];
                       String sampleVals = (format == null) ?      // case where there is no FORMAT column,
                                               null :              // e.g. no populated per-sample column of data in the VCF
                                           (firstSampleCol >= 0) ? // case where there is at least one populated sample column
                                           createFormatJson(formats, format, vals[i]) :
                                               null;               // case where no sample column is defined at all (annotation VCF)
                       String sampleId   = (firstSampleCol >= 0) ? columns[i] : "";


                       return new OutputRow(chrom, pos, id, ref, alt, qual, filter, info, sampleVals, sampleId);     
                   });
           });
       }
       finally{}
   }
}
$$
;


-- UDFs to help parse out allele values and reduce query complexity!
CREATE OR REPLACE SECURE FUNCTION allele1 (ref varchar, alt array, gt varchar)
RETURNS varchar as
$$
case when contains(gt, '|') then
   case when strtok(gt, '|', 1) = '0' then ref else alt[strtok(gt, '|', 1)::integer-1] end
else
   case when strtok(gt, '/', 1) = '0' then ref else alt[strtok(gt, '/', 1)::integer-1] end
end
$$
;


CREATE OR REPLACE SECURE FUNCTION allele2 (ref varchar, alt array, gt varchar)
RETURNS varchar as
$$
case when contains(gt, '|') then
   case when strtok(gt, '|', 2) = '0' then ref else alt[strtok(gt, '|', 2)::integer-1] end
else
   case when strtok(gt, '/', 2) = '0' then ref else alt[strtok(gt, '/', 2)::integer-1] end
end
$$
;
:::

## Snowflakeã§å…¬é–‹ã‚²ãƒãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ‰±ã†æº–å‚™ã‚’ã™ã‚‹
ä½•ã¯ã¨ã‚‚ã‚ã‚Œã€ã¾ãšã¯è§£æã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨æ„ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚illuminaãŒOpen Data Registryã§åˆ©ç”¨å¯èƒ½ãªä¸€èˆ¬å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ãƒãƒªã‚¢ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã¨ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’AWSä¸Šã«ãƒ›ã‚¹ãƒˆã—ã¦ãã‚Œã¦ã„ã‚‹ã¿ãŸã„ãªã®ã§ã“ã¡ã‚‰ã‚’ä½¿ã„ã¾ã™ã€‚ä»Šå›ã¯1000-Genomesãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰ã€3,202äººåˆ†ã®DRAGENã‚’ç”¨æ„ã—ã¾ã™ã€‚ã¡ãªã¿ã«DRAGENã¨ã¯Dynamic Read Analysis for Genomicsã®ç•¥ã§ã€Illuminaç¤¾ãŒæä¾›ã—ã¦ã„ã‚‹ãƒã‚¤ã‚ªã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹ã®ãŸã‚ã®å°‚é–€çš„ãªãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãŠã‚ˆã³ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã‚’æŒ‡ã—ã¾ã™ã€‚DRAGENã¯é«˜é€Ÿã§ç²¾åº¦ã®é«˜ã„ã‚²ãƒãƒ é…åˆ—æƒ…å ±ã®è§£æã‚’è¡Œã„ã€ã‚·ãƒ¼ã‚±ãƒ³ã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒãƒªã‚¢ãƒ³ãƒˆã‚’æ¤œå‡ºã™ã‚‹èƒ½åŠ›ã‚’æŒã£ã¦ã„ã¾ã™ã€‚ã¾ãŸã“ã¡ã‚‰ã®é…åˆ—ã¯GRCh38ã¨ã„ã†ãƒ’ãƒˆã®ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã‚²ãƒãƒ ã«ãƒãƒƒãƒ”ãƒ³ã‚°ã•ã‚ŒãŸé…åˆ—ã‚µãƒ³ãƒ—ãƒ«ã§ã™ã€‚

Open Data Repositoryã®S3ã¨å¤–éƒ¨ã‚¹ãƒ†ãƒ¼ã‚¸ã‚’ä½œæˆã—ã¾ã™ã€‚ä¸‹è¨˜ã‚¯ã‚¨ãƒªã®å®Ÿè¡Œæ™‚é–“ã¯xsã‚µã‚¤ã‚ºã§4åˆ†59ç§’ã§ã—ãŸã€‚
```sql
-- Data location from 1000-genomes files
-- Create stage including Directory Table
create or replace stage dragen_all
   directory = (enable = true)
   url = 's3://1000genomes-dragen-3.7.6/data/individuals/hg38-graph-based'
   file_format = (type = CSV compression = AUTO)
;
```
VCF (Variant Call Format) ãƒ•ã‚¡ã‚¤ãƒ«ãŒå–å¾—ã•ã‚Œã¦ã„ã¾ã™ã€‚VCFãƒ•ã‚¡ã‚¤ãƒ«ã¨ã¯ã€ã‚²ãƒãƒ é…åˆ—ã®ãƒãƒªã‚¢ãƒ³ãƒˆï¼ˆéºä¼çš„å¤‰ç•°ï¼‰ã‚’è¡¨ã™ãŸã‚ã«ç”¨ã„ã‚‰ã‚Œã‚‹æ¨™æº–çš„ãªãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™ã€‚ãã‚Œãã‚Œã®VCFãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ç´„500ä¸‡è¡Œã®ãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚


ã‚¹ãƒ†ãƒ¼ã‚¸ã®å®šç¾©ãŒçµ‚ã‚ã‚Šã€è§£æé–¢æ•°ã‚’å®šç¾©ãŒçµ‚ã‚ã‚‹ã¨ã‚¯ã‚¨ãƒªã‚’å©ã‘ã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚"ãƒãƒ¼ãƒ‰ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã•ã‚ŒãŸ "ãƒãƒªã‚¢ãƒ³ãƒˆã¨ã—ã¦è¡¨ç¾ã•ã‚ŒãŸ8ã¤ã®ã‚²ãƒãƒ ã®ãƒ©ãƒ³ãƒ€ãƒ ãªã‚»ãƒƒãƒˆã‚’æ‰±ã†ã«ã¯ã€æ¬¡ã®ã‚ˆã†ãªã‚¯ã‚¨ãƒªãƒ¼ã§ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚’å¾—ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

```sql
-- Sample query from Directory Table showing a pattern selection of 8 Dragan files
SELECT * FROM DIRECTORY( @dragen_all )
where relative_path rlike '/HG0011[0-7].*.hard-filtered.vcf.gz'
;
```

![](https://storage.googleapis.com/zenn-user-upload/28543107cb9d-20230714.png)

VCFãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ã–ã£ã¨è¦‹ã‚‹ã«ã¯ã€æ¬¡ã®ã‚ˆã†ãªã‚¯ã‚¨ãƒªãƒ¼ã‚’ä½¿ç”¨ã—ã¦æœ€åˆã®200è¡Œã‚’å–å¾—ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
```sql
-- Sample query from Directory Table showing a pattern selection of 8 Dragan files
SELECT * FROM DIRECTORY( @dragen_all )
where relative_path rlike '/HG0011[0-7].*.hard-filtered.vcf.gz'
;
```
![](https://storage.googleapis.com/zenn-user-upload/4d3d1371b85a-20230715.png)
ç‰¹å®šã®SampleIDã‚’å«ã‚€ã€Chromã€Posã€Refãªã©ã®æ˜ç¢ºãªã‚«ãƒ©ãƒ ã‚’å«ã‚€æ§‹é€ åŒ–ã•ã‚ŒãŸçµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚åŠæ§‹é€ åŒ–ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®INFOã¨SAMPLEVALSã«ã¯ã€ãã®å ´æ‰€ã§ã®ã‚²ãƒãƒ ã‚³ãƒ¼ãƒ«ã®æ§˜ã€…ãªç‰¹å¾´ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚ã“ã‚Œã‚‰ã®åŠæ§‹é€ åŒ–ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‹ã‚‰å¿…è¦ãªå€¤ã‚’ç°¡å˜ã«é¸æŠã—ã€æ“ä½œã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

ã‚²ãƒãƒ ãƒãƒªã‚¢ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æ ¼ç´ã™ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã—ã€ã‚µãƒ³ãƒ—ãƒ«ã”ã¨ã«1ãƒãƒªã‚¢ãƒ³ãƒˆã‚ãŸã‚Š1è¡Œã§ãƒãƒªã‚¢ãƒ³ãƒˆã‚’è¡¨ç¾ã—ã¾ã™ã€‚

```sql
create or replace table GENOTYPES_BY_SAMPLE (
   CHROM       varchar,
   POS         integer,
   ID          varchar,
   REF         varchar,
   ALT         array  ,
   QUAL        integer,
   FILTER      varchar,
   INFO        variant,
   SAMPLE_ID   varchar,
   VALS        variant,
   ALLELE1     varchar,
   ALLELE2     varchar,
   FILENAME    varchar
);
```

ãã—ã¦æœ€å¾Œã«ã€å…ˆã«å®šç¾©ã—ãŸVCFè§£æé–¢æ•°ã‚’ä½¿ç”¨ã™ã‚‹ã‚¯ã‚¨ãƒªãƒ¼ã‚’ãƒ†ãƒ¼ãƒ–ãƒ«ã«æŠ•å…¥ã—ã€ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒªã‚¹ãƒˆã¸ã®JOINã‚’ä»‹ã—ã¦ã€ç›®çš„ã®å„ãƒ•ã‚¡ã‚¤ãƒ«ã«é©ç”¨ã—ã¦ã„ãã¾ã™ã€‚ï¼ˆç§ã®ç’°å¢ƒã§ã¯xsã‚µã‚¤ã‚ºã§6åˆ†15ç§’ã§ã—ãŸã€‚ï¼‰
```sql
insert into GENOTYPES_BY_SAMPLE (
   CHROM       ,
   POS         ,
   ID          ,
   REF         ,
   ALT         ,
   QUAL        ,
   FILTER      ,
   INFO        ,
   SAMPLE_ID   ,
   VALS        ,
   ALLELE1     ,
   ALLELE2     ,
   FILENAME    )
with file_list as (
   SELECT file_url, relative_path FROM DIRECTORY( @dragen_all )
   --where relative_path rlike '.*.hard-filtered.vcf.gz'  //select all 3202 genomes
   where relative_path rlike '/HG0011[0-7].*.hard-filtered.vcf.gz'  //selection of 8 genomes
   --where relative_path rlike '/HG00[0-2][0-9][0-9].*.hard-filtered.vcf.gz'  //selection of 122 genomes
 order by random()  //temporary hint to maximize parallelism  
)
select
   replace(CHROM, 'chr','')         , 
   POS           ,
   ID            ,
   REF           ,
   split(ALT,','),
   QUAL          ,
   FILTER        ,
   INFO          , 
   SAMPLEID      ,
   SAMPLEVALS    ,
   allele1(ref, split(ALT,','), SAMPLEVALS:GT::varchar) as ALLELE1,
   allele2(ref, split(ALT,','), SAMPLEVALS:GT::varchar) as ALLELE2,
   split_part(relative_path, '/',3)
from file_list,
    table(ingest_vcf(BUILD_SCOPED_FILE_URL(@dragen_all, relative_path), 0)) vcf
;
```

## ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã®ã‚¯ã‚¨ãƒªãƒ¼ä¾‹
ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰åˆæœŸç‰¹æ€§ã‚’å¾—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚
ä»¥ä¸‹ã®ã‚¯ã‚¨ãƒªã¯ã€ã‚µãƒ³ãƒ—ãƒ«ã”ã¨ã®ãƒãƒªã‚¢ãƒ³ãƒˆã‚³ãƒ¼ãƒ«ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ·±åº¦ï¼ˆDPï¼‰å€¤ã®åˆ†å¸ƒã‚’è¦ç´„ã—ã€ã“ã®é‡è¦ãªå“è³ªæŒ‡æ¨™ã®5ã€10ã€50ã€90ã€95ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«å€¤ã‚’ç¤ºã—ã¦ã„ã¾ã™

```sql
-- Percentile distributions of Sampling Depths
select distinct sample_id,
  percentile_cont(.05) within group (order by vals:DP::number) over (partition by(sample_id)),
  percentile_cont(.1) within group (order by vals:DP::number) over (partition by(sample_id)),
  percentile_cont(.5) within group (order by vals:DP::number) over (partition by(sample_id)),
  percentile_cont(.9) within group (order by vals:DP::number) over (partition by(sample_id)),
  percentile_cont(.95) within group (order by vals:DP::number) over (partition by(sample_id))
from genotypes_by_sample
;

```
![](https://storage.googleapis.com/zenn-user-upload/47a2e37a3199-20230715.png)

VCFï¼ˆVariant Call Formatï¼‰ãƒ‡ãƒ¼ã‚¿ã‚’è§£æã™ã‚‹éš›ã®æ³¨æ„ç‚¹ã§ã™ãŒã€åŒã˜éºä¼å­å‹ã§ã‚‚é›†å›£é–“ã§æ­£è¦åŒ–ã•ã‚Œã¦ã„ãªã„ãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã†ã¨ãã«ã¯ã€å…·ä½“çš„ãªå¯¾ç«‹éºä¼å­ï¼ˆã‚¢ãƒ¬ãƒ«ï¼‰ã®å€¤ã‚’ç›´æ¥ä½¿ç”¨ã™ã‚‹ã“ã¨ãŒæ¨å¥¨ã•ã‚Œã¦ã„ã¾ã™ã€‚

åˆ¥ã®ä¾‹ã§ã¯ã€å„æŸ“è‰²ä½“ã§è¦³å¯Ÿã•ã‚ŒãŸãƒãƒªã‚¢ãƒ³ãƒˆã‚³ãƒ¼ãƒ«ã®é‡ã‚’ã€ãƒ›ãƒ¢æ¥åˆãƒãƒªã‚¢ãƒ³ãƒˆã‹ãƒ˜ãƒ†ãƒ­æ¥åˆãƒãƒªã‚¢ãƒ³ãƒˆã‹ã§ç‰¹å¾´ä»˜ã‘ã€ALLELE1ã¨ALLELE2ã®å€¤ã‚’ä½¿ã£ã¦æ±ºå®šã—ã¦ã„ã¾ã™ã€‚ã‚¤ãƒ³ã‚¸ã‚§ã‚¹ãƒˆã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ã€ã‚µãƒ³ãƒ—ãƒ«ã”ã¨ã«å‘¼ã³å‡ºã•ã‚ŒãŸãƒãƒªã‚¢ãƒ³ãƒˆï¼ˆéå‚ç…§ï¼‰ã®ã¿ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã®ã§ã€ãƒ›ãƒ¢æ¥åˆã®å‚ç…§ã‚«ã‚¦ãƒ³ãƒˆã¯ã™ã¹ã¦0ã«ãªã‚Šã¾ã™ã€‚

```sql
-- Total Count of variant calls by type, per chrom
select chrom,
   sum(case when allele1 = ref and allele2 = ref then 1 else 0 end) as homozref,
   sum(case when allele1 != allele2 then 1 else 0 end) as heterozalt,
   sum(case when allele1 != ref and allele2 = allele1 then 1 else 0 end) as homozalt
from Genotypes_by_sample
where try_to_number(chrom) is not null
group by 1 order by try_to_number(chrom);
```

![](https://storage.googleapis.com/zenn-user-upload/0dbfa0fd4396-20230715.png)


## ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã¨è¡¨ç¾å‹ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®çµ±åˆ
ã„ã‚ˆã„ã‚ˆéºä¼å­å‹ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚„è¡¨ç¾å‹æƒ…å ±ã¨çµã³ã¤ã‘ã¦ã„ãã¾ã™ã€‚
ClinVarãƒ‡ãƒ¼ã‚¿ã®ç¾åœ¨ã®ã‚³ãƒ”ãƒ¼ã¯AWSã«ã‚ˆã£ã¦Parquetãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ç®¡ç†ã•ã‚Œã¦ã„ã‚‹ã®ã§å–ã‚Šè¾¼ã‚“ã§ã„ãã¾ã™ã€‚ã¡ãªã¿ã«ClinVarã¯ã€ã‚¢ãƒ¡ãƒªã‚«å›½ç«‹è¡›ç”Ÿç ”ç©¶æ‰€ï¼ˆNational Institutes of Health: NIHï¼‰ãŒé‹å–¶ã™ã‚‹ç„¡æ–™ã®å…¬é–‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§ã€äººé–“ã®éºä¼å¤‰ç•°ã¨ãã®å¥åº·ã¸ã®å½±éŸ¿ï¼ˆç‰¹ã«éºä¼æ€§ç–¾æ‚£ï¼‰ã«é–¢ã™ã‚‹æƒ…å ±ã‚’é›†ç´„ã—ã¦ã„ã¾ã™ã€‚

ã¾ãšs3ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æŒ‡ã™ã‚¹ãƒ†ãƒ¼ã‚¸ã‚’å®šç¾©ã—ã€Parquetã‚’æ§‹é€ åŒ–ãƒ†ãƒ¼ãƒ–ãƒ«ã«ã‚¤ãƒ³ã‚¸ã‚§ã‚¹ãƒˆã—ã¾ã™ï¼š

```sql
create or replace stage clinvar
   url = 's3://aws-roda-hcls-datalake/clinvar_summary_variants'
   file_format = (type = PARQUET)
;


create or replace table CLINVAR (
 chrom                  varchar(2),
 pos                    number    ,
 ref                    varchar   ,
 alt                    varchar   ,
 ALLELEID               number    ,
 chromosomeaccession    varchar   ,        
 CLNSIG                 varchar   ,
 clinsigsimple          number    ,  
 cytogenetic            varchar   ,
 geneid                 number    ,
 genesymbol             varchar   ,
 guidelines             varchar   ,
 hgnc_id                varchar   ,
 lastevaluated          varchar   ,  
 name                   varchar   ,   
 numbersubmitters       number    ,     
 origin                 varchar   ,
 originsimple           varchar   , 
 otherids               varchar   ,
 CLNDISB                array     ,
 CLNDN                  array     ,
 rcvaccession           array     , 
 CLNREVSTAT             varchar   ,
 RS                     number    ,
 startpos               number    ,
 stoppos                number    ,
 submittercategories    number    ,        
 testedingtr            varchar   ,
 type                   varchar   ,
 variationid            number    ,
 full_annotation        variant  
);


insert into CLINVAR
select
   $1:chromosome                 ::varchar(2)  chrom,
   $1:positionvcf                ::number      pos,
   $1:referenceallelevcf         ::varchar     ref,
   $1:alternateallelevcf         ::varchar     alt,
   $1:alleleid                   ::number      ALLELEID,
   $1:chromosomeaccession        ::varchar     chromosomeaccession,
   $1:clinicalsignificance       ::varchar     CLNSIG,
   $1:clinsigsimple              ::number      clinsigsimple,
   $1:cytogenetic                ::varchar     cytogenetic,
   $1:geneid                     ::number      geneid,
   $1:genesymbol                 ::varchar     genesymbol,
   $1:guidelines                 ::varchar     guidelines,
   $1:hgnc_id                    ::varchar     hgnc_id,
   $1:lastevaluated              ::varchar     lastevaluated,
   $1:name                       ::varchar     name,   
   $1:numbersubmitters           ::number      numbersubmitters,
   $1:origin                     ::varchar     origin,
   $1:originsimple               ::varchar     originsimple,
   $1:otherids                   ::varchar     otherids,
   split($1:phenotypeids::varchar,  '|')       CLNDISB,
   split($1:phenotypelist::varchar, '|')       CLNDN,
   split($1:rcvaccession::varchar,  '|')       rcvaccession,
   $1:reviewstatus               ::varchar     CLNREVSTAT,
   $1:rsid_dbsnp                 ::number      RS,
   $1:start                      ::number      startpos,
   $1:stop                       ::number      stoppos,
   $1:submittercategories        ::number      submittercategories,
   $1:testedingtr                ::varchar     testedingtr,
   $1:type                       ::varchar     type,
   $1:variationid                ::number      variationid,
   $1                            ::variant     full_annotation
FROM '@clinvar/variant_summary/'
where $1:assembly = 'GRCh38'
order by chrom, pos
;
```

æ–°ãŸã«å–ã‚Šè¾¼ã‚€ï¼ˆã‚¤ãƒ³ã‚¸ã‚§ã‚¹ãƒˆã™ã‚‹ï¼‰ãƒ‡ãƒ¼ã‚¿ã‚’GRCh38ãƒ¬ãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã‚²ãƒãƒ ã¨ä¸€è‡´ã•ã›ã€ã™ã§ã«å–ã‚Šè¾¼ã¾ã‚ŒãŸ1000 Genomesãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ã®æ•´åˆæ€§ã‚’å–ã£ã¦ã„ãã¾ã™ã€‚

è¡¨ç¾å‹ãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦ã¯ã€å„ã‚µãƒ³ãƒ—ãƒ«ã®åœ°ç†çš„èµ·æºã¨æ€§åˆ¥ã€ãŠã‚ˆã³ã‚µãƒ³ãƒ—ãƒ«é–“ã®å®¶æ—é€£é–ã‚’è¨˜è¿°ã—ãŸã€Œpanelã€ãƒ†ãƒ¼ãƒ–ãƒ«ã®ã¿æ‰±ã†ã“ã¨ãŒå¯èƒ½ã§ã™ã€‚ãã‚Œã§ã‚‚ã€ã‚²ãƒãƒ ã®çµåˆã¨ã‚µãƒ³ãƒ—ãƒ«ã®ç‰¹æ€§ã‚’è€ƒå¯Ÿã™ã‚‹ã®ã«ååˆ†ãªææ–™ã§ã™ã€‚
```sql
create or replace stage population
   url = 's3://1000genomes/1000G_2504_high_coverage/additional_698_related/'
   file_format = (type = CSV compression = AUTO field_delimiter=' ' skip_header=1)
   ;


create or replace table panel (
  Sample_ID        varchar,
  Family_ID        varchar,
  Father_ID        varchar,
  Mother_ID        varchar,
  Gender           varchar,
  Population       varchar,
  Superpopulation  varchar
);


insert into panel
select $2, $1, $3, $4, case when $5 = 1 then 'male' else 'female' end, $6, $7
from '@population/20130606_g1k_3202_samples_ped_population.txt'
;
```


## ã™ã¹ã¦ã‚’ã¾ã¨ã‚ã‚‹

panelãƒ‡ãƒ¼ã‚¿ã¨ã‚²ãƒãƒ ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã—ã¦èˆˆå‘³ã‚ã‚‹ãƒãƒªã‚¢ãƒ³ãƒˆè§£æãŒã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚ãã‚Œã§ã¯å…·ä½“çš„ãªè§£æã‚’è¡Œã£ã¦ã„ãã¾ã—ã‚‡ã†ï¼

ç‰¹å®šã®äººå£çµ±è¨ˆæ¡ä»¶ï¼ˆä»Šå›ã¯ã€ã‚¤ã‚®ãƒªã‚¹ã®å¥³æ€§ï¼‰ã®äººã€…ã«ã¤ã„ã¦ã€æŒ‡å®šã•ã‚ŒãŸã‚¯ãƒ­ãƒã‚½ãƒ¼ãƒ ï¼ˆã‚¯ãƒ­ãƒã‚½ãƒ¼ãƒ 10ï¼‰ã®ç‰¹å®šã®ä½ç½®ç¯„å›²ï¼ˆ100,000ã‹ã‚‰500,000ã®é–“ï¼‰ã®éºä¼å­å‹æƒ…å ±ã‚’å–å¾—ã—ã¦ã¿ã¾ã™ã€‚

```sql
-- Example Query:  Britain Female Samples for subset of chrom 10
select g.sample_id, chrom, pos, ref, alt, vals:GT::varchar gt,
   allele1,
   allele2
from genotypes_by_sample g
join panel p on p.sample_id = g.sample_id
where chrom = '10' and pos between 100000 and 500000
   and population = 'GBR'
   and gender = 'female'
limit 100;
```
æ®µã€…ã¨è§£æãƒ‡ãƒ¼ã‚¿ã£ã½ããªã£ã¦ãã¾ã—ãŸã­ã€‚
![](https://storage.googleapis.com/zenn-user-upload/b6c4ba904135-20230715.png)

å„ã‚«ãƒ©ãƒ ã®è§£èª¬ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚
**sample_id** - ã‚µãƒ³ãƒ—ãƒ«IDã€‚ã“ã“ã§è¨€ã†ã‚µãƒ³ãƒ—ãƒ«ã¨ã¯ã€å…·ä½“çš„ã«ã¯å€‹ã€…ã®ã‚²ãƒãƒ ã‚µãƒ³ãƒ—ãƒ«ã‚’æŒ‡ã—ã¾ã™ã€‚
**chrom** - ã‚¯ãƒ­ãƒã‚½ãƒ¼ãƒ ç•ªå·ã€‚ã“ã®ã‚¯ã‚¨ãƒªã§ã¯ã€ã‚¯ãƒ­ãƒã‚½ãƒ¼ãƒ 10ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã™ã€‚
**pos** - ã‚¯ãƒ­ãƒã‚½ãƒ¼ãƒ ä¸Šã®ä½ç½®ã€‚ã“ã®ã‚¯ã‚¨ãƒªã§ã¯ã€ã‚¯ãƒ­ãƒã‚½ãƒ¼ãƒ 10ã®100,000ã‹ã‚‰500,000ã®é–“ã®ä½ç½®ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã™ã€‚
**ref** - ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ï¼ˆå‚ç…§ï¼‰ã‚¢ãƒªãƒ«ã€‚é€šå¸¸ã¯ãƒ’ãƒˆã‚²ãƒãƒ ã®ã€Œæ¨™æº–çš„ãªã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«è¦‹ã‚‰ã‚Œã‚‹å¡©åŸºï¼ˆDNAã®æ–‡å­—ï¼‰ã§ã™ã€‚
**alt** - ä»£æ›¿ã‚¢ãƒªãƒ«ã€‚å¤‰ç•°ãŒè¦‹ã‚‰ã‚Œã‚‹å ´åˆã®å¡©åŸºï¼ˆDNAã®æ–‡å­—ï¼‰ã§ã™ã€‚
**gt** - éºä¼å­å‹ã€‚ã“ã‚Œã¯å€‹ä½“ãŒãã®ä½ç½®ã§æŒã£ã¦ã„ã‚‹å…·ä½“çš„ãªã‚¢ãƒªãƒ«ã®ãƒšã‚¢ã‚’ç¤ºã—ã¾ã™ã€‚
**allele1 ã¨ allele2** - éºä¼å­å‹ãŒç¤ºã™ã€é¸æŠã•ã‚ŒãŸ2ã¤ã®ã‚¢ãƒªãƒ«ã€‚

æ¬¡ã«éºä¼æ€§å¤§è…¸ãŒã‚“ã«é–¢é€£ã™ã‚‹ã™ã¹ã¦ã®ä½ç½®ã‚’èª¿ã¹ã¾ã™ã€‚æŸ“è‰²ä½“ã‚„ä½ç½®ã‚’æ˜ç¤ºçš„ã«æŒ‡å®šã™ã‚‹å¿…è¦ã¯ãªãã€ClinVarã¸ã®çµåˆã«ã‚ˆã£ã¦æš—é»™çš„ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãŒé©ç”¨ã•ã‚Œã‚‹ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ï¼š

```sql
-- Example Query -- locations associated with hereditary colon cancer
select   g.chrom, g.pos, g.ref, allele1, allele2, count (sample_id)
from genotypes_by_sample g
join clinvar c
   on c.chrom = g.chrom and c.pos = g.pos and c.ref = g.ref
where
   array_contains('Hereditary nonpolyposis colorectal neoplasms'::variant, CLNDN)
group by 1,2,3,4,5
order by 1,2,5
;
```

ClinVarã®CLNDNã‚«ãƒ©ãƒ ã‚’æ‰±ã†å ´åˆã€ã‚«ãƒ©ãƒ ã«è¤‡æ•°ã®å€¤ãŒå«ã¾ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã§Snowflakeã®ARRAY_CONTAINSé–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ç›®çš„ã®æŒ‡æ¨™ã‚’æŒ‡å®šã—ã¾ã™ã€‚æ¬¡ã«ã€ãƒãƒªã‚¢ãƒ³ãƒˆã‚³ãƒ¼ãƒ«ã®ALLELE1ã¾ãŸã¯ALLEL2ãŒã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã¨ä¸€è‡´ã™ã‚‹ãƒãƒªã‚¢ãƒ³ãƒˆå€¤ã®ã¿ã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹ã“ã¨ã§ã€ã‚¯ã‚¨ãƒªã‚’çµã‚Šè¾¼ã‚€ã“ã¨ãŒã§ãã¾ã™ã€‚

```sql
-- Example Query -- specific variants associated with hereditary colon cancer
select   g.chrom, g.pos, g.ref, c.alt clinvar_alt, genesymbol, allele1, allele2, count (sample_id)
from genotypes_by_sample g
join clinvar c
   on c.chrom = g.chrom and c.pos = g.pos and c.ref = g.ref
   and ((Allele1= c.alt) or (Allele2= c.alt))
where
   array_contains('Hereditary nonpolyposis colorectal neoplasms'::variant, CLNDN)
group by 1,2,3,4,5,6,7
order by 1,2,5
;
```


## ã‚²ãƒãƒ ãƒ‡ãƒ¼ã‚¿ã®ä¾¡å€¤ã‚’å¼•ãå‡ºã™ãã®ä»–ã®æ–¹æ³•
æ¥­ç•Œæ¨™æº–ã®VCFãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ä½œæˆã•ã‚ŒãŸã‚²ãƒãƒ ãƒ‡ãƒ¼ã‚¿ã‚’ã€æ‚£è€…ãƒ‡ãƒ¼ã‚¿ã‚„ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã¨çµ„ã¿åˆã‚ã›ã¦å–ã‚Šè¾¼ã¿ã€çµåˆã€è§£æã§ãã‚‹ã ã‘ã§ã‚‚snowflakeã®æŸ”è»Ÿæ€§ã‚’æ„Ÿã˜ã¾ã™ãŒã€ä»–ã«ã‚‚æ§˜ã€…ãªãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«é©ç”¨ã§ãã‚‹ã“ã¨ãŒè€ƒãˆã‚‰ã‚Œã¾ã™ã€‚ä»¥ä¸‹ã®ã‚ˆã†ãªã“ã¨ã«å¿œç”¨ã§ãã‚‹ã¨è¿°ã¹ã‚‰ã‚Œã¦ã„ã¾ã—ãŸã€‚

ãƒ»é¸æŠã—ãŸãƒ‡ãƒ¼ã‚¿ã‚µãƒ–ã‚»ãƒƒãƒˆã‚’ã‚³ãƒ”ãƒ¼ã™ã‚‹ã“ã¨ãªãã€å…±åŒä½œæ¥­è€…ã¨å®‰å…¨ã«ãƒ­ãƒ¼ãƒ«ã‚¬ãƒãƒŠãƒ³ã‚¹ä»˜ãã§å…±æœ‰ã™ã‚‹ã€‚
ãƒ»é›†å›£å…¨ä½“ã®ãƒ‡ãƒ¼ã‚¿ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’è“„ç©ã™ã‚‹ãŸã‚ã«ã€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã”ã¨ã«æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ã‚¿ãƒ«ã«å–ã‚Šè¾¼ã‚€ã€‚
ãƒ»ç”Ÿã®ã‚²ãƒãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã€Œæ­£è¦åŒ–ã€ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã«å¤‰æ›ã™ã‚‹
ãƒ»GVCFãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®å–ã‚Šæ‰±ã„ã¨é«˜å“è³ªãƒ¬ãƒ³ã‚¸ãƒªãƒ¼ãƒ‰ã‹ã‚‰ã®ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã‚³ãƒ¼ãƒ«ã®å°å‡º
ãƒ»ã‚µãƒ³ãƒ—ãƒ«IDã¾ãŸã¯ã‚²ãƒãƒ å†…ã®ä½ç½®ã«ã‚ˆã‚‹é«˜é€Ÿæ¤œç´¢ã‚’å¯èƒ½ã«ã™ã‚‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°æŠ€è¡“
ãƒ»ãƒãƒªã‚¢ãƒ³ãƒˆã¨è¡¨ç¾å‹ã‚’çµ„ã¿åˆã‚ã›ãŸãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ã€æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¾ãŸã¯ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã®å…¥åŠ›ã¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç”Ÿæˆã™ã‚‹ã€‚


## å€‹äººçš„ã«ãƒã‚¤ã‚ªã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹ã™ã‚‹ä¸Šã§snowflakeã«è¶³ã‚Šãªã„ã¨ã“ã‚
å€‹äººçš„ã«snowflakeã§ãƒã‚¤ã‚ªã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹ã‚’ã™ã‚‹ã«ã¯**1.ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†ã®å®Ÿè¡Œ**ã¨**2.ãƒã‚¤ã‚ªã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚µãƒãƒ¼ãƒˆ**ãŒå¿…è¦ã ã¨æ€ã„ã¾ã™ã€‚

### 1.ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†ã®å®Ÿè¡Œ
ç”Ÿå‘½ç§‘å­¦ã®é ˜åŸŸã§ã¯ã€æ§˜ã€…ãªåˆ†æãƒ„ãƒ¼ãƒ«ãŒå­˜åœ¨ã—ã¾ã™ã€‚ãã‚Œã‚‰ã¯å˜ç‹¬ã§ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚‚å¯èƒ½ã§ã™ãŒã€ã‚ˆã‚Šè¤‡é›‘ãªåˆ†æã‚„è§£æã‚’è¡Œã†ãŸã‚ã«ã¯ã€ã“ã‚Œã‚‰ã®ãƒ„ãƒ¼ãƒ«ã‚’çµ„ã¿åˆã‚ã›ã¦ä¸€é€£ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã—ã€ãã®ä¸Šã§å‡¦ç†ã‚’è¡Œã†ã“ã¨ãŒä¸€èˆ¬çš„ã§ã™ã€‚RNA-seqãƒ‡ãƒ¼ã‚¿ã®è§£æã‚’ä¾‹ã«ã¨ã£ã¦ã‚‚fasterq-dump(sra-toolkit)â†’QC(FastQC)â†’ãƒªãƒ¼ãƒ‰ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆï¼ˆSTARã€Hisat2ï¼‰â†’ãƒªãƒ¼ãƒ‰ã‚«ã‚¦ãƒ³ãƒˆï¼ˆsalmonï¼‰â†’æ­£è¦åŒ–(DESeq2ã‚„edgeR)â†’ä¸‹æµè§£æï¼ˆggplot2ã‚„enrichmentè§£æï¼‰ãªã©ã‚ã‚Šã¾ã™ã€‚snowflakeä¸Šã«ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹ã«å®Ÿè¡Œã§ãã‚‹ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒªã‚½ãƒ¼ã‚¹ã‚’ã‚­ãƒ£ãƒ‘ã‚·ãƒ†ã‚£èª²é‡‘ã§ä½¿ãˆã‚‹ã‚ˆã†ã«ãªã‚‹ã¨æŸ”è»Ÿãªè§£æãŒã§ãã‚‹ã¨æ€ã„ã¾ã™ã€‚åŠ ãˆã¦Nextflowã‚„KNIMEãªã©ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†è¨€èªãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã‚‹ã®ã‚‚é‡è¦ã§ã™ã€‚

ä»Šå¹´ã®snowflakesummitã§ç™ºè¡¨ã•ã‚ŒãŸsnowpark container servicesã ã¨k8sä¸Šã§ã‚³ãƒ³ãƒ†ãƒŠãŒå‹•ã‹ã›ã‚‹ã®ã§Dockerã‚’ä½¿ã£ã¦Linuxç’°å¢ƒã‚’æ§‹ç¯‰ã™ã‚Œã°ã€ãƒã‚¤ã‚ªã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹ã®åˆ†æãƒ„ãƒ¼ãƒ«ã‚’è‡ªç”±è‡ªåœ¨ã«æ‰±ã†ã“ã¨ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è‡ªèº«ã®ãƒ‹ãƒ¼ã‚ºã«æœ€é©ãªç’°å¢ƒã‚’æ§‹ç¯‰ã—ã€æœ€æ–°ã®ç§‘å­¦çš„æ‰‹æ³•ã‚’æ´»ç”¨ã—ã¦ç ”ç©¶ã‚’é€²ã‚ã‚‹ã“ã¨ãŒå¯èƒ½ã«ãªã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚
![](https://storage.googleapis.com/zenn-user-upload/0c6bf3c41d0f-20230715.png)
https://medium.com/snowflake/snowpark-container-services-a-tech-primer-99ff2ca8e741


### 2.ãƒã‚¤ã‚ªã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚µãƒãƒ¼ãƒˆ
snowflakeã§pythonã‚’ä½¿ãˆã‚‹snowpark for pythonã§ã™ãŒã€ãƒã‚¤ã‚ªã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹ç³»ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¯ã‚ã¾ã‚Šå……å®Ÿã—ã¦ãŠã‚Šã¾ã›ã‚“ã€‚Snowflake conda channelã§ã¯bioç³»ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨ã„ã£ãŸã‚‰biopythonãã‚‰ã„ã§ã—ãŸã€‚![](https://storage.googleapis.com/zenn-user-upload/283a24566b13-20230715.png)

https://repo.anaconda.com/pkgs/snowflake/
æ®‹å¿µãªãŒã‚‰ã€single cell RNA-seqãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã‚ã‚‹scanpyã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ã¿ãŸã„ã§ã™ã€‚ã‚·ãƒ³ã‚°ãƒ«ã‚»ãƒ«ãƒ‡ãƒ¼ã‚¿ã¯è¶…å·¨å¤§ãƒ‡ãƒ¼ã‚¿ã§ã‚ã‚‹ãŸã‚snowflakeä¸Šã§ã•ã°ã‘ã‚‹ã¨å‡¦ç†ãŒåŠ¹ç‡åŒ–ã•ã‚Œã¾ã™ã€‚snowsightä¸Šã«10X genomics ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚µãƒ³ãƒ—ãƒ«ã®UMAPãƒ—ãƒ­ãƒƒãƒˆã‚’è¡¨ç¤ºã•ã›ã‚‹æœªæ¥ã‚’å€‹äººçš„ã«ã¯å¿ƒå¾…ã¡ã«ã—ã¦ã„ã¾ã™ã€‚çŸ¥ã‚‰ãªã„æ–¹ã®ãŸã‚ã«ã€ç§ãŒéå»ã«è§£æã—ãŸpbmcãƒ‡ãƒ¼ã‚¿ã«å…ç–«ç´°èƒã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è‡ªå‹•ä»˜ä¸ã—ãŸUMAPãƒ—ãƒ­ãƒƒãƒˆã‚’ä¾‹ã¨ã—ã¦è¼‰ã›ã¦ãŠãã¾ã™ã€‚
![](https://storage.googleapis.com/zenn-user-upload/785362194549-20230715.png)
	
ãƒã‚¤ã‚ªç³»ã§ã‚‚pythonã¯äººæ°—ã§ã™ãŒã€Rã‚‚ä¸€å®šæ•°ã®äººæ°—ãŒã‚ã‚Šã¾ã™ã€‚ç›¸äº’ã§ã§ãã‚‹ã“ã¨ãŒç•°ãªã£ã¦ãŠã‚Šã€ä¾ç„¶ã¨ã—ã¦Rã§ã—ã‹ã§ããªã„è§£æã‚‚å¤šãå­˜åœ¨ã™ã‚‹ã“ã¨ã‹ã‚‰ã€ãƒã‚¤ã‚ªã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚·ãƒ£ãƒ³ã®ä¸­ã«ã¯Python/Rã®äºŒåˆ€æµã‚’å–ã£ã¦ã„ã‚‹æ–¹ã‚‚å­˜åœ¨ã—ã¾ã™ã€‚å…ˆç¨‹ç´¹ä»‹ã—ãŸsnowpark container servicesã§ã¯Rã®ãƒ­ã‚´ãŒã‚ã£ãŸã®ã§RãŒä½¿ãˆã‚‹ã‚ˆã†ã«ãªã‚‹ã“ã¨ã‚‚æœŸå¾…ã—ã¦ã„ã¾ã™ã€‚
	
### ã—ã‹ã—ã§ãã‚‹ã“ã¨ã‚‚å¤šã„
ã—ã‹ã—ã€snowflakeä¸Šã§ã§ãã‚‹ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹ã‚‚ç¾çŠ¶ã®æ®µéšã§ååˆ†ã«ã‚ã‚Šã¾ã™ã€‚ãƒãƒ³ã‚ºã‚ªãƒ³ã§å–ã‚Šä¸Šã’ãŸå…¬å…±ã®S3ã‚’å¤–éƒ¨ã‚¹ãƒ†ãƒ¼ã‚¸ã¨ã—ã¦çµ±åˆã—ã¦å–ã‚Šè¾¼ã‚€ã®ã¯ã€è¤‡é›‘ãªETLå‡¦ç†ã‚„APIã§TSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¼•ã£å¼µã£ã¦ãã‚‹ã¨ã„ã£ãŸç…©é›‘ã•ã‹ã‚‰é–‹æ”¾ã—ã¦ãã‚Œã¾ã™ã€‚ã¾ãŸãƒã‚¤ã‚ªãƒ‡ãƒ¼ã‚¿ã¯è‡¨åºŠæ¤œä½“ã¨ã„ã£ãŸæ‚£è€…ã®ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã«å½“ãŸã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’å–ã‚Šæ‰±ã†æ©Ÿä¼šã‚‚å¤šãã€ã“ã®ã‚ãŸã‚Šã¯snowflakeã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¹ã‚­ãƒ³ã‚°ã‚„ã‚»ã‚­ãƒ¥ã‚¢ãªãƒ‡ãƒ¼ã‚¿å…±æœ‰æ©Ÿèƒ½ãŒæ´»ã‹ã›ã‚‹ãƒã‚¤ãƒ³ãƒˆã§ã™ã€‚
ã¾ãŸãƒã‚¤ã‚ªãƒ‡ãƒ¼ã‚¿ã¯ãã®è¤‡é›‘æ€§ã‹ã‚‰å¾€ã€…ã«ã—ã¦åŠæ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã¨ãªã£ã¦ã„ã‚‹å ´åˆã‚‚å¤šãã€snowflakeã ã¨åŠæ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã®ã¾ã¾å–ã‚Šè¾¼ã‚“ã§ã‚¯ã‚¨ãƒªã§ãã‚‹ã®ã¯é­…åŠ›çš„ãªè¦ç´ ã¨è¨€ãˆã¾ã™ã€‚ã“ã®ã‚ãŸã‚Šã€SAM/BAMã¨ã„ã£ãŸæ¬¡ä¸–ä»£ã‚·ãƒ¼ã‚±ãƒ³ã‚µãƒ¼ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾ã—ã¦é«˜é€Ÿã§è§£æã‚’ã‹ã‘ã‚‹ã¨ã„ã£ãŸãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã‚‚è¿‘ã„å°†æ¥ã§ã¯å¯èƒ½ã«ãªã‚Šãã†ã§ã™ã€‚
	
ã¾ãŸæœ€è¿‘ã®snowflakeã¯streamlitå‘¨ã‚ŠãŒå……å®Ÿã—ã¦ãã¾ã—ãŸã€‚ä¸€åº¦ã‚²ãƒãƒ ãƒ‡ãƒ¼ã‚¿ã‚’snowflakeä¸Šã®ãƒ†ãƒ¼ãƒ–ãƒ«ã«æ§‹ç¯‰ã™ã‚Œã°ã€streamlitã«ã‚ˆã‚‹å¯è¦–åŒ–ã§ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ãŒå¯èƒ½ã§ã™ã€‚ä¾‹ãˆã°ä»¥ä¸‹ã¯covid19ã®é‡ç—‡åº¦ã«å¿œã˜ãŸå„éºä¼å­ç™ºç¾é‡ï¼ˆãƒªãƒ¼ãƒ‰ã‚«ã‚¦ãƒ³ãƒˆï¼‰ã‚’ç®±ã²ã’ãƒ—ãƒ­ãƒƒãƒˆã«ã¦å¯è¦–åŒ–ã—ã¦ã„ã¾ã™ã€‚RNA-seqãƒ‡ãƒ¼ã‚¿ã®ã‚ˆã†ãªå·¨å¤§ãƒ‡ãƒ¼ã‚¿ã‚’æ ¼ç´â†’streamlitã§å¯è¦–åŒ–ã¨ã„ã£ãŸæµã‚Œã¯æœ‰åŠ¹ãªæ‰‹æ®µã¨ãªã‚Šãˆã¾ã™ã€‚
![](https://storage.googleapis.com/zenn-user-upload/af72f86e3c4f-20230715.png)
https://kuanrongchan-covid19-severity-app-t7l38g.streamlit.app/
		
## çµ‚ã‚ã‚Šã«
ä»Šå›ã¯snowflakeã§è¡Œã†ãƒã‚¤ã‚ªã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹ã®å¯èƒ½æ€§ã‚’æ¢æ±‚ã—ã¦ã¿ã¾ã—ãŸã€‚ã¡ãªã¿ã«snowflakeã‚’datawarehouseã¨ã—ã¦ä½¿ã£ã¦è§£æã—ãŸè«–æ–‡ã¯ã‚ã‚‹ã‹Pubmedæ¤œç´¢ã—ã¦ã¿ã¾ã—ãŸãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚
![](https://storage.googleapis.com/zenn-user-upload/bc28efa767ea-20230715.png)
å€‹äººçš„ã«ã¯GigaScienceã‚ãŸã‚Šã®ã‚¸ãƒ£ãƒ¼ãƒŠãƒ«ã§snowparkã‚’ä½¿ã£ãŸã‚ªãƒŸã‚¯ã‚¹è§£æã‚„é«˜é€Ÿé…åˆ—æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã‚ãŸã‚Šã§è«–æ–‡åŒ–ã™ã‚‹ã®ã‚‚é¢ç™½ãã†ã ãªã¨æ„Ÿã˜ã¦ã¾ã™ã€‚

